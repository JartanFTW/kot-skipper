{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "128abe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb82aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale = 1/255)\n",
    "validation = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0e9a03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1305 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train.flow_from_directory(\"train\", target_size=(40, 47), batch_size=10, class_mode = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "062308a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1305 images belonging to 6 classes.\n",
      "Found 1305 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train.flow_from_directory(\"train\", target_size=(40, 47), batch_size=10, class_mode = \"binary\")\n",
    "\n",
    "validation_dataset = train.flow_from_directory(\"validation\", target_size=(40, 47), batch_size=10, class_mode = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fe1b5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bd72ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [ tf.keras.layers.Flatten(input_shape=(40, 47, 3)),\n",
    "     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(6)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "923b4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             optimizer = \"adam\",\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe058382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 3.3262 - accuracy: 0.3400 - val_loss: 2.0652 - val_accuracy: 0.3556\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 1.6776 - accuracy: 0.4105 - val_loss: 1.1230 - val_accuracy: 0.5724\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 1s 67ms/step - loss: 0.8754 - accuracy: 0.7800 - val_loss: 0.9331 - val_accuracy: 0.5739\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 1s 67ms/step - loss: 0.6415 - accuracy: 0.7700 - val_loss: 0.6217 - val_accuracy: 0.7464\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.4788 - accuracy: 0.8300 - val_loss: 0.4882 - val_accuracy: 0.7862\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.3978 - accuracy: 0.9300 - val_loss: 0.3313 - val_accuracy: 0.9670\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2733 - accuracy: 0.9800 - val_loss: 0.2486 - val_accuracy: 0.9709\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 0.2856 - accuracy: 0.9500 - val_loss: 0.1708 - val_accuracy: 0.9831\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1914 - accuracy: 0.9800 - val_loss: 0.1551 - val_accuracy: 0.9923\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.1931 - accuracy: 0.9800 - val_loss: 0.1266 - val_accuracy: 0.9923\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9916\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9923\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9908\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9923\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 0.0634 - accuracy: 0.9900 - val_loss: 0.0618 - val_accuracy: 0.9954\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.0760 - accuracy: 0.9900 - val_loss: 0.0690 - val_accuracy: 0.9923\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.0880 - accuracy: 0.9900 - val_loss: 0.0634 - val_accuracy: 0.9939\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 0.0961 - accuracy: 0.9800 - val_loss: 0.0927 - val_accuracy: 0.9954\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 1s 67ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9893\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.0458 - accuracy: 0.9900 - val_loss: 0.0404 - val_accuracy: 0.9962\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9969\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 1s 86ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9931\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9969\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 0.0510 - accuracy: 0.9900 - val_loss: 0.0440 - val_accuracy: 0.9977\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9977\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 0.0293 - accuracy: 0.9895 - val_loss: 0.0276 - val_accuracy: 0.9962\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9985\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.0604 - accuracy: 0.9900 - val_loss: 0.0748 - val_accuracy: 0.9801\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.0509 - accuracy: 0.9900 - val_loss: 0.0414 - val_accuracy: 0.9977\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9969\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_dataset,\n",
    "                     steps_per_epoch = 10,\n",
    "                     epochs = 30,\n",
    "                     validation_data = validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9eee1c08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 images belonging to 6 classes.\n",
      "3/3 - 0s - loss: 0.0923 - accuracy: 0.9524 - 31ms/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# TESTING ACCURACY\n",
    "\n",
    "test_images = train.flow_from_directory(\"test\", target_size=(40, 47), batch_size=10, class_mode = \"binary\")\n",
    "\n",
    "loss, acc = model.evaluate(test_images, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e135e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
